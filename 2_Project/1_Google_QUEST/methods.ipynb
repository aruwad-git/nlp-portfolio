{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dd772-8a37-4885-9cf8-244c69425b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines.\n",
    "\n",
    "# Define Custom Model.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, checkpoint, num_labels, additional_feature_dim):\n",
    "        super(CustomModel, self).__init__()\n",
    "        \n",
    "        # Load pretrained transformer.\n",
    "        self.transformer = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "        # Expose the transformer's config.\n",
    "        self.config = self.transformer.config\n",
    "        \n",
    "        # Combine transformer outputs with additional features\n",
    "        transformer_hidden_size = self.transformer.config.hidden_size\n",
    "        self.fc1 = nn.Linear(transformer_hidden_size + additional_feature_dim, num_labels)\n",
    "        \n",
    "#       self.fc2 = nn.Linear(256, num_labels)   # For complex Head.\n",
    "#       self.dropout = nn.Dropout(0.1)          # For dropout.\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, additional_features):\n",
    "        # Transformer output.\n",
    "        transformer_output = self.transformer(\n",
    "            input_ids      = input_ids,\n",
    "            attention_mask = attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token for concatenation.\n",
    "        cls_output     = transformer_output.last_hidden_state[:, 0, :]\n",
    "        combined_input = torch.cat([cls_output, additional_features], dim=1)\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "#       x = self.dropout(torch.relu(self.fc1(combined_input)))\n",
    "        output = self.fc1(combined_input)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Define HF Wrapper for Custom Model.\n",
    "class HuggingFaceModelWrapper(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model         # Custom model.\n",
    "        self.config     = base_model.config  # Expose the base model's config.\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, additional_features, labels=None):\n",
    "        # Forward pass through the base model.\n",
    "        output = self.base_model(input_ids           = input_ids, \n",
    "                                 attention_mask      = attention_mask, \n",
    "                                 additional_features = additional_features)\n",
    "        \n",
    "        # If labels are provided, calculate loss.\n",
    "        logits = output\n",
    "        loss   = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.BCEWithLogitsLoss()\n",
    "            loss    = loss_fn(logits, labels)\n",
    "        \n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "    def prepare_inputs_for_generation(self, *args, **kwargs):\n",
    "        # Delegate to the base model.\n",
    "        return self.base_model.prepare_inputs_for_generation(*args, **kwargs)\n",
    "\n",
    "# Spearman's Corr.\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions    = np.argmax(logits, axis=1) if logits.ndim == 3 else logits\n",
    "\n",
    "    # Calculate Spearman's correlation for each label.\n",
    "    spearman_corrs = []\n",
    "    for i in range(labels.shape[1]):\n",
    "        corr, _ = spearmanr(predictions[:, i], labels[:, i])\n",
    "        spearman_corrs.append(corr)\n",
    "\n",
    "    # Return the mean of Spearman's correlation.\n",
    "    mean_spearman = np.nanmean(spearman_corrs)  # Handle NaNs if any.\n",
    "    return {\"spearman\": mean_spearman}\n",
    "\n",
    "# Convert datasets, `df` -> `ds`.\n",
    "def preprocess_data(df, labels):\n",
    "    return {\n",
    "        \"input_ids\"             : list(df['input_ids']),\n",
    "        \"attention_mask\"        : list(df['attention_mask']),\n",
    "        \"additional_features\"   : df.iloc[:, :-2].values.tolist(),  \n",
    "        \"labels\"                : labels.to_numpy().tolist()        \n",
    "    }\n",
    "\n",
    "# Method to Check Rank.\n",
    "def check_rank(score):\n",
    "    leaderboard = pd.read_csv('./leaderboard.csv')\n",
    "    num_team    = len(leaderboard)\n",
    "    mean        = leaderboard['Score'].mean()\n",
    "    median      = leaderboard['Score'].median()\n",
    "\n",
    "    my_rank = (leaderboard['Score'] >= my_score).sum()\n",
    "\n",
    "    print(f'My Rank = {my_rank} / {num_team}')\n",
    "    print(f'My Score = {score:.4f}')\n",
    "    print(f'Mean = {mean:.4f}')\n",
    "    print(f'Median = {median:.4f}')\n",
    "\n",
    "# Plot Learning Curve.\n",
    "def plot_learning_curve(history):\n",
    "    eval_loss  = [log[\"eval_loss\"] for log in history if \"eval_loss\" in log]\n",
    "    train_loss = [log[\"loss\"] for log in history if \"loss\" in log]\n",
    "    spear_loss = [log[\"eval_spearman\"] for log in history if \"loss\" in log]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Training Loss curve\n",
    "    plt.plot(\n",
    "        [log[\"step\"] for log in history if \"loss\" in log],\n",
    "        train_loss,\n",
    "        label=\"Training Loss\",\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    \n",
    "    # Validation Loss curve\n",
    "    plt.plot(\n",
    "        [log[\"step\"] for log in history if \"eval_loss\" in log],\n",
    "        eval_loss,\n",
    "        label=\"Validation Loss\",\n",
    "        marker=\"x\",\n",
    "    )\n",
    "\n",
    "    # Spearman Loss curve\n",
    "    plt.plot(\n",
    "        [log[\"step\"] for log in history if \"eval_loss\" in log],\n",
    "        spear_loss,\n",
    "        label=\"Spearman Loss\",\n",
    "        marker=\"x\",\n",
    "    )\n",
    "    \n",
    "    # Labels and legends\n",
    "    plt.title(\"Training and Validation Loss Curve\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
